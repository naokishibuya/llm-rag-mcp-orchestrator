[project]
name = "llm-rag-chat"
version = "0.1.0"
description = "LLM RAG Chat Demo with multi-provider support"
requires-python = ">=3.12,<3.14"  # avoid pydantic v1 compatibility warning
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn>=0.35.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "numpy>=1.26.0",
    "requests>=2.31.0",
    "fastmcp>=2.12.0",
    "mcp>=1.16.0",
    "anthropic>=0.40.0",
    "openai>=1.0.0",
    "google-genai>=1.0.0",
    "ollama>=0.4.0",
    "tqdm>=4.66.0",
    "python-dotenv>=1.0.0",
    # LangGraph for model-agnostic orchestration
    "langgraph>=0.2.0",
    "langchain-core>=0.3.0",
    "httpx>=0.27.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "ruff>=0.15.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/backend"]

[tool.ruff]
line-length = 120
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I", "W"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
